{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx0uD2Nc-Lpd"
      },
      "source": [
        "### Pre-Trained Model with Fine-Tuning - BART"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:55:44.922893Z",
          "iopub.status.busy": "2023-12-12T18:55:44.922613Z",
          "iopub.status.idle": "2023-12-12T18:55:48.321554Z",
          "shell.execute_reply": "2023-12-12T18:55:48.320293Z",
          "shell.execute_reply.started": "2023-12-12T18:55:44.922869Z"
        },
        "id": "TaennITo-Lph",
        "outputId": "467f1339-e92a-480f-ce60-fc98450fe89c",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from kaggle_secrets import UserSecretsClient\n",
        "import wandb\n",
        "\n",
        "user_secrets = UserSecretsClient()\n",
        "my_secret = user_secrets.get_secret(\"wandb_api\")\n",
        "wandb.login(key=my_secret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:56:04.478154Z",
          "iopub.status.busy": "2023-12-12T18:56:04.477815Z",
          "iopub.status.idle": "2023-12-12T18:56:44.290917Z",
          "shell.execute_reply": "2023-12-12T18:56:44.289858Z",
          "shell.execute_reply.started": "2023-12-12T18:56:04.478123Z"
        },
        "id": "8WfLx9Zr-Lpi",
        "outputId": "29180bbb-b45b-418b-8a29-9184df625e46",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /usr/share/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /usr/share/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import re\n",
        "import requests\n",
        "import string\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "tokens = spacy.load(\"en_core_web_sm\")\n",
        "from bs4 import BeautifulSoup\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "from functools import reduce\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('brown')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.stats import norm\n",
        "from nltk.corpus import wordnet as wn\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.metrics import edit_distance\n",
        "\n",
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, Flatten, Dense\n",
        "\n",
        "import torch\n",
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer\n",
        "from transformers import TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import pipeline\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
        "\n",
        "import datasets\n",
        "from datasets import load_metric\n",
        "from datasets import Dataset\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using device:\", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:56:44.292871Z",
          "iopub.status.busy": "2023-12-12T18:56:44.292156Z",
          "iopub.status.idle": "2023-12-12T18:56:44.608793Z",
          "shell.execute_reply": "2023-12-12T18:56:44.607951Z",
          "shell.execute_reply.started": "2023-12-12T18:56:44.292841Z"
        },
        "id": "0Zxf6k3a-Lpj",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/kaggle/input/final-data/final_data (1).csv')\n",
        "data.drop_duplicates(['Target'], inplace=True)\n",
        "data.drop_duplicates(['Clues'], inplace=True)\n",
        "data.dropna(axis=0, inplace=True)\n",
        "\n",
        "data_train, data_test = train_test_split(data, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:56:46.083344Z",
          "iopub.status.busy": "2023-12-12T18:56:46.082981Z",
          "iopub.status.idle": "2023-12-12T18:56:46.116751Z",
          "shell.execute_reply": "2023-12-12T18:56:46.115876Z",
          "shell.execute_reply.started": "2023-12-12T18:56:46.083313Z"
        },
        "id": "sWvLn9sp-Lpk",
        "outputId": "e00be944-06b0-44c6-fdd5-d6a90eeef4ad",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Target</th>\n",
              "      <th>Clues</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>35353</th>\n",
              "      <td>hub</td>\n",
              "      <td>parental supervision focal point event revolve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10950</th>\n",
              "      <td>pomatomus saltatrix</td>\n",
              "      <td>pomatomus percoid fish bluefish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33784</th>\n",
              "      <td>ground level</td>\n",
              "      <td>elevation floor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24173</th>\n",
              "      <td>conservation of energy</td>\n",
              "      <td>conservation law of thermodynamics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34932</th>\n",
              "      <td>historic period</td>\n",
              "      <td>era history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6167</th>\n",
              "      <td>gastrocybe</td>\n",
              "      <td>secotiaceae fungus genus gastrocybe lateritia</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39957</th>\n",
              "      <td>manner of speaking</td>\n",
              "      <td>expressive style paralanguage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15487</th>\n",
              "      <td>allowance account</td>\n",
              "      <td>reserve account</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41657</th>\n",
              "      <td>muff</td>\n",
              "      <td>handwear blunder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51607</th>\n",
              "      <td>spelter</td>\n",
              "      <td>zinc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                       Target  \\\n",
              "35353                     hub   \n",
              "10950     pomatomus saltatrix   \n",
              "33784            ground level   \n",
              "24173  conservation of energy   \n",
              "34932         historic period   \n",
              "6167               gastrocybe   \n",
              "39957      manner of speaking   \n",
              "15487       allowance account   \n",
              "41657                    muff   \n",
              "51607                 spelter   \n",
              "\n",
              "                                                   Clues  \n",
              "35353  parental supervision focal point event revolve...  \n",
              "10950                    pomatomus percoid fish bluefish  \n",
              "33784                                    elevation floor  \n",
              "24173                 conservation law of thermodynamics  \n",
              "34932                                        era history  \n",
              "6167       secotiaceae fungus genus gastrocybe lateritia  \n",
              "39957                      expressive style paralanguage  \n",
              "15487                                    reserve account  \n",
              "41657                                   handwear blunder  \n",
              "51607                                               zinc  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def cleantext(text):\n",
        "    string = re.sub(r'\\([^)]*\\)', '', string)\n",
        "    string = re.sub(\"[^a-zA-Z.]\", \" \", string)\n",
        "    string = text.lower()\n",
        "    return string\n",
        "\n",
        "ctargets, cclues = [], []\n",
        "\n",
        "for i in data['Target']:\n",
        "    ctargets.append(cleantext(i))\n",
        "\n",
        "for j in data['Clues']:\n",
        "    cclues.append(cleantext(j))\n",
        "\n",
        "cdata = pd.DataFrame(columns=['Target', 'Clues'])\n",
        "cdata['Target'] = ctargets\n",
        "cdata['Clues'] = cclues\n",
        "\n",
        "cdata.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:56:46.118292Z",
          "iopub.status.busy": "2023-12-12T18:56:46.117944Z",
          "iopub.status.idle": "2023-12-12T18:56:46.156722Z",
          "shell.execute_reply": "2023-12-12T18:56:46.155815Z",
          "shell.execute_reply.started": "2023-12-12T18:56:46.118261Z"
        },
        "id": "VPGLRAru-Lpk",
        "outputId": "d6963f2f-6e3c-499b-9f4e-835bf7ab93f1",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(57933, 2)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cdata.replace('', np.nan, inplace=True)\n",
        "cdata.dropna(axis=0, inplace=True)\n",
        "\n",
        "cdata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "76199ab997aa4e5086f640fb5e4d18ef",
            "e0aa882df11e4d91be073d5720fb611b",
            "95d68ea2c1e6486c956fc9a867942c58",
            "ac58e40d782040879e57dc12f5a8c85d"
          ]
        },
        "execution": {
          "iopub.execute_input": "2023-12-12T18:56:46.869126Z",
          "iopub.status.busy": "2023-12-12T18:56:46.868854Z",
          "iopub.status.idle": "2023-12-12T18:56:47.848013Z",
          "shell.execute_reply": "2023-12-12T18:56:47.847091Z",
          "shell.execute_reply.started": "2023-12-12T18:56:46.869103Z"
        },
        "id": "JCTp6L-R-Lpk",
        "outputId": "e45685f7-f86e-41c9-835d-d932c8299acd",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "76199ab997aa4e5086f640fb5e4d18ef",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.72k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e0aa882df11e4d91be073d5720fb611b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "95d68ea2c1e6486c956fc9a867942c58",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac58e40d782040879e57dc12f5a8c85d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model_id = 'facebook/bart-base'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "metric = load_metric(\"rouge\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_id).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:56:47.922851Z",
          "iopub.status.busy": "2023-12-12T18:56:47.922462Z",
          "iopub.status.idle": "2023-12-12T18:56:47.935925Z",
          "shell.execute_reply": "2023-12-12T18:56:47.934994Z",
          "shell.execute_reply.started": "2023-12-12T18:56:47.922816Z"
        },
        "id": "olfuDfzU-Lpl",
        "outputId": "2dce2d03-12ea-450c-cc06-1737559d9ec7",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'input_ids': [[0, 8687, 9230, 2918, 2]], 'attention_mask': [[1, 1, 1, 1, 1]], 'labels': [[0, 27739, 2918, 2]]}"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tokenize_input(data, max_len=400):\n",
        "    return tokenizer(data['Target'], max_length=max_len, truncation=True)\n",
        "\n",
        "def tokenize_target(data, max_len=50):\n",
        "    with tokenizer.as_target_tokenizer():\n",
        "        return tokenizer(data['Clues'], max_length=max_len, truncation=True)\n",
        "\n",
        "def datapreprocessing(data):\n",
        "    tokenized_input = tokenize_input(data)\n",
        "    tokenized_target = tokenize_target(data)\n",
        "    tokenized_input[\"labels\"] = tokenized_target[\"input_ids\"]\n",
        "    return tokenized_input\n",
        "\n",
        "cdata_train, cdata_test = train_test_split(cdata, test_size = 0.25, random_state = 42)\n",
        "data_train = Dataset.from_pandas(cdata_train)\n",
        "data_test = Dataset.from_pandas(cdata_test)\n",
        "\n",
        "datapreprocessing(data_train[:1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:57:13.885133Z",
          "iopub.status.busy": "2023-12-12T18:57:13.884795Z",
          "iopub.status.idle": "2023-12-12T18:57:13.896262Z",
          "shell.execute_reply": "2023-12-12T18:57:13.895234Z",
          "shell.execute_reply.started": "2023-12-12T18:57:13.885101Z"
        },
        "id": "BPTGAK_q-Lpl",
        "outputId": "3291bc88-9437-4062-c8e4-5a43545e4c81",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "dict_keys(['Target', 'Clues', '__index_level_0__', 'input_ids', 'attention_mask', 'labels'])\n",
            "{'Target': 'teamsters union', 'Clues': 'industrial union', '__index_level_0__': 12974, 'input_ids': [0, 8687, 9230, 2918, 2], 'attention_mask': [1, 1, 1, 1, 1], 'labels': [0, 27739, 2918, 2]}\n"
          ]
        }
      ],
      "source": [
        "data_train_tokenized = data_train.map(datapreprocessing, batched=True)\n",
        "data_test_tokenized = data_test.map(datapreprocessing, batched=True)\n",
        "\n",
        "print(data_train_tokenized[0].keys())\n",
        "print(data_train_tokenized[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:57:23.185607Z",
          "iopub.status.busy": "2023-12-12T18:57:23.184841Z",
          "iopub.status.idle": "2023-12-12T18:57:25.805819Z",
          "shell.execute_reply": "2023-12-12T18:57:25.804906Z",
          "shell.execute_reply.started": "2023-12-12T18:57:23.185571Z"
        },
        "id": "ZgQm_2LS-Lpl",
        "outputId": "bd897a3b-a103-40db-efec-d37f2deace69",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'summary_text': 'apple mango'}]"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def textgen(type, text, min_length=1, max_length=5):\n",
        "    target = [e['text'] for e in type(text, min_length = min_length, max_length = max_length)]\n",
        "    display(HTML(pd.DataFrame({\"Clues\":target, \"Target\":text}).to_html()))\n",
        "\n",
        "pretrain = pipeline(\"text-generation\", model = model, tokenizer = tokenizer, device = 0)\n",
        "\n",
        "input = \"Apple Mango Melon\"\n",
        "cinput = cleantext(input)\n",
        "\n",
        "pretrain(cinput, min_length = 3, max_length = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5D4YMH3Z-Lpm"
      },
      "outputs": [],
      "source": [
        "def decode_predictions(preds):\n",
        "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
        "    return [\"\\n\".join(nltk.sent_tokenize(p.strip())) for p in decoded_preds]\n",
        "\n",
        "def decode_targets(tgts):\n",
        "    processed_targets = np.where(tgts != -100, tgts, tokenizer.pad_token_id)\n",
        "    decoded_targets = tokenizer.batch_decode(processed_targets, skip_special_tokens=True)\n",
        "    return [\"\\n\".join(nltk.sent_tokenize(t.strip())) for t in decoded_targets]\n",
        "\n",
        "def calculate_metrics(decoded_preds, decoded_tgts):\n",
        "    eval_result = metric.compute(predictions=decoded_preds, references=decoded_tgts, use_stemmer=True)\n",
        "    return {k: v.mid.fmeasure * 100 for k, v in eval_result.items()}\n",
        "\n",
        "def compute_average_length(preds):\n",
        "    lens = [np.count_nonzero(p != tokenizer.pad_token_id) for p in preds]\n",
        "    return np.mean(lens)\n",
        "\n",
        "def compute_metrics(evaluations):\n",
        "    predictions, targets = evaluations\n",
        "\n",
        "    processed_preds = decode_predictions(predictions)\n",
        "    processed_targets = decode_targets(targets)\n",
        "    metrics_result = calculate_metrics(processed_preds, processed_targets)\n",
        "\n",
        "    avg_length = compute_average_length(predictions)\n",
        "    metrics_result[\"gen_len\"] = avg_length\n",
        "\n",
        "    return {k: round(v, 4) for k, v in metrics_result.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:57:48.320850Z",
          "iopub.status.busy": "2023-12-12T18:57:48.320584Z",
          "iopub.status.idle": "2023-12-12T18:57:48.538089Z",
          "shell.execute_reply": "2023-12-12T18:57:48.537223Z",
          "shell.execute_reply.started": "2023-12-12T18:57:48.320827Z"
        },
        "id": "N4xronlF-Lpm",
        "outputId": "1d372f21-889e-4da6-c7c5-ea4c065ce767",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50265, 768, padding_idx=1)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartEncoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50265, 768, padding_idx=1)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 768)\n",
              "      (layers): ModuleList(\n",
              "        (0-5): 6 x BartDecoderLayer(\n",
              "          (self_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartAttention(\n",
              "            (k_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (v_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (final_layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=50265, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model = model)\n",
        "\n",
        "args = Seq2SeqTrainingArguments('text-gen-bart',\n",
        "                                num_train_epochs = 3, evaluation_strategy = \"epoch\",\n",
        "                                logging_steps = 100, learning_rate = 2e-5, weight_decay = 0.01,\n",
        "                                per_device_train_batch_size = 10, per_device_eval_batch_size = 10,\n",
        "                                save_total_limit = 3, predict_with_generate = True, fp16 = True)\n",
        "\n",
        "model_trainer = Seq2SeqTrainer(model, args, train_dataset = data_train_tokenized,\n",
        "                               eval_dataset = data_test_tokenized, data_collator = data_collator,\n",
        "                               tokenizer = tokenizer, compute_metrics = compute_metrics)\n",
        "\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T18:57:48.539590Z",
          "iopub.status.busy": "2023-12-12T18:57:48.539280Z",
          "iopub.status.idle": "2023-12-12T19:42:47.540720Z",
          "shell.execute_reply": "2023-12-12T19:42:47.539711Z",
          "shell.execute_reply.started": "2023-12-12T18:57:48.539563Z"
        },
        "id": "7kXwfST1-Lpm",
        "outputId": "9047ff96-8c05-4ece-f097-16cac0f61b2f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamaanvoraa\u001b[0m (\u001b[33mnlp-amaan\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/kaggle/working/wandb/run-20231212_185749-wo5usyrr</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nlp-amaan/huggingface/runs/wo5usyrr' target=\"_blank\">cosmic-sound-5</a></strong> to <a href='https://wandb.ai/nlp-amaan/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/nlp-amaan/huggingface' target=\"_blank\">https://wandb.ai/nlp-amaan/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/nlp-amaan/huggingface/runs/wo5usyrr' target=\"_blank\">https://wandb.ai/nlp-amaan/huggingface/runs/wo5usyrr</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='6519' max='6519' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [6519/6519 44:24, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.320400</td>\n",
              "      <td>3.962089</td>\n",
              "      <td>19.400200</td>\n",
              "      <td>2.901900</td>\n",
              "      <td>19.071100</td>\n",
              "      <td>19.077800</td>\n",
              "      <td>6.652100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.030500</td>\n",
              "      <td>3.851192</td>\n",
              "      <td>19.173000</td>\n",
              "      <td>3.141800</td>\n",
              "      <td>18.820400</td>\n",
              "      <td>18.827600</td>\n",
              "      <td>6.748300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.957900</td>\n",
              "      <td>3.822068</td>\n",
              "      <td>19.398000</td>\n",
              "      <td>3.231200</td>\n",
              "      <td>19.017000</td>\n",
              "      <td>19.034700</td>\n",
              "      <td>6.775500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=6519, training_loss=4.191124352122912, metrics={'train_runtime': 2698.4987, 'train_samples_per_second': 48.304, 'train_steps_per_second': 2.416, 'total_flos': 659920626892800.0, 'train_loss': 4.191124352122912, 'epoch': 3.0})"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-12-12T19:59:35.307012Z",
          "iopub.status.busy": "2023-12-12T19:59:35.306305Z",
          "iopub.status.idle": "2023-12-12T19:59:35.605361Z",
          "shell.execute_reply": "2023-12-12T19:59:35.604276Z",
          "shell.execute_reply.started": "2023-12-12T19:59:35.306978Z"
        },
        "id": "apQpf5qn-Lpn",
        "outputId": "ad25fee6-bcb4-4f63-cd74-5a75a17e9666",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Clues</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>monocot genus spanish moss bromeliaceae</td>\n",
              "      <td>monoc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>traveler framework shoe</td>\n",
              "      <td>traveler</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>calamity</td>\n",
              "      <td>calam</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "generator = pipeline(\"text-generation\", model = model, tokenizer = tokenizer, device = 0)\n",
        "\n",
        "idx = random.sample(range(0, len(data_test)), k=3)\n",
        "sdata = [data_test[i]['Clues'] for i in idx]\n",
        "textgen(generator, sdata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y9L1KQdC-Lpn"
      },
      "outputs": [],
      "source": [
        "PATH = '/kaggle/working/text-gen-bart/' + 'bart'\n",
        "\n",
        "if not os.path.isdir(PATH):\n",
        "    os.mkdir(PATH)\n",
        "    model.save_pretrained(PATH)\n",
        "else:\n",
        "    print('Model Present')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "datasetId": 4143657,
          "sourceId": 7171655,
          "sourceType": "datasetVersion"
        },
        {
          "datasetId": 4148582,
          "sourceId": 7178280,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30616,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
